+++
chapter = false
title = "4.1 Overview"
weight = 1

+++
**Choose Real-Time or Batch Predictions**

We need to understand the application and business context to choose between real-time and batch predictions. Are we trying to optimize for latency or throughput? Does the application require our models to scale automatically throughout the day to handle cyclic traffic requirements? Do we plan to compare models in production through A/B tests?

If our application requires low latency, then we should deploy the model as a real-time API to provide super-fast predictions on single prediction requests over HTTPS, for example. We can deploy, scale, and compare our model prediction servers with SageMaker Endpoints using the REST API protocol with HTTPS and JSON, as shown in Figure 9-1.

![](/images/deploy.png)

_Figure 9-1. Deploy a model as a real-time REST endpoint._

For less latency-sensitive applications that require high throughput, we should deploy our model as a batch job to perform batch predictions on large amounts of data in S3, for example. We will use SageMaker Batch Transform to perform the batch predictions along with a data store like Amazon RDS or DynamoDB to productionize the predictions, as shown in Figure 9-2.

![](/images/batch.png)

_Figure 9-2. Deploying our model as a batch job to perform batch predictions on large amounts of data in S3 using SageMaker Batch Transform._

**Real-Time Predictions with SageMaker Endpoints**

we will deploy our model as a REST API using SageMaker Endpoints. SageMaker Endpoints are, by default, distributed containers. Applications invoke our models through a simple RESTful interface, as shown in Figure 9-3, which shows the model deployed across multiple cluster instances and Availability Zones for higher availability. 

![](/images/rest.png)

_Figure 9-3. Application invoking our highly available model hosted on a REST endpoint._

**Deploy Model Using SageMaker Python SDK**

There are two ways to deploy the model using the SageMaker Python SDK. We can call deploy() on a model object, or we can call deploy() on the SageMaker estimator object that we used to train the model.