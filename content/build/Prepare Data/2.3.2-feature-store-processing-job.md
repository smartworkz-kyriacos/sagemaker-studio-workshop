+++
chapter = false
title = "Lab 2.3.2 Processing Job"
weight = 18

+++
**Feature Transformation with Amazon a SageMaker Processing Job and Scikit-Learn**

In this notebook, we convert raw text into BERT embeddings. This will allow us to perform natural language processing tasks such as text classification.

Typically a machine learning (ML) process consists of a few steps. First, gathering data with various ETL jobs, then pre-processing the data, featurizing the dataset by incorporating standard techniques or prior knowledge, and finally training an ML model using an algorithm.

Often, distributed data processing frameworks such as Scikit-Learn are used to pre-process data sets to prepare them for training. In this notebook, we'll use Amazon SageMaker Processing, and leverage the power of Scikit-Learn in a managed SageMaker environment to run our processing workload.

> **NOTE: THIS NOTEBOOK WILL TAKE 5-10 MINUTES TO COMPLETE. PLEASE BE PATIENT.**

![](https://raw.githubusercontent.com/smartworkz-kyriacos/data-science-on-aws/1bc7efe6931b75614b570f5f1c6f1c762abd8973/06_prepare/img/prepare_dataset_bert.png)

![](https://raw.githubusercontent.com/smartworkz-kyriacos/data-science-on-aws/1bc7efe6931b75614b570f5f1c6f1c762abd8973/06_prepare/img/processing.jpg)

**Contents**

1. Setup Environment
2. Setup Input Data
3. Setup Output Data
4. Build a Scikit-Learn container for running the processing job
5. Run the Processing Job using Amazon SageMaker
6. Inspect the Processed Output Data

**Setup Environment**

Let's start by specifying:

* The S3 bucket and prefixes that you use for training and model data. Use the default bucket specified by the Amazon SageMaker session.
* The IAM role ARN is used to give processing and training access to the dataset.

In \[ \]:

    import sagemaker
    import boto3
    
    sess = sagemaker.Session()
    role = sagemaker.get_execution_role()
    bucket = sess.default_bucket()
    region = boto3.Session().region_name
    
    sm = boto3.Session().client(service_name="sagemaker", region_name=region)
    s3 = boto3.Session().client(service_name="s3", region_name=region)
    

**Setup Input Data**

In \[ \]:

    %store -r s3_public_path_tsv
    

In \[ \]:

    try:
        s3_public_path_tsv
    except NameError:
        print("++++++++++++++++++++++++++++++++++++++++++++++++++++++++")
        print("[ERROR] Please run the notebooks in the INGEST section before you continue.")
        print("++++++++++++++++++++++++++++++++++++++++++++++++++++++++")
    

In \[ \]:

    print(s3_public_path_tsv)
    

In \[ \]:

    %store -r s3_private_path_tsv
    

In \[ \]:

    try:
        s3_private_path_tsv
    except NameError:
        print("++++++++++++++++++++++++++++++++++++++++++++++++++++++++")
        print("[ERROR] Please run the notebooks in the INGEST section before you continue.")
        print("++++++++++++++++++++++++++++++++++++++++++++++++++++++++")
    

In \[ \]:

    print(s3_private_path_tsv)
    

In \[ \]:

    raw_input_data_s3_uri = "s3://{}/amazon-reviews-pds/tsv/".format(bucket)
    print(raw_input_data_s3_uri)
    

In \[ \]:

    !aws s3 ls $raw_input_data_s3_uri
    

**Run the Processing Job using Amazon SageMaker**

Next, use the Amazon SageMaker Python SDK to submit a processing job using our custom python script.

**Review the Processing Script**

In \[ \]:

    !pygmentize preprocess-scikit-text-to-bert-feature-store.py
    

Run this script as a processing job. You also need to specify one `ProcessingInput` with the `source` the argument for the Amazon S3 bucket and `destination` is where the script reads this data from `/opt/ml/processing/input` (inside the Docker container.) All local paths inside the processing container must begin with `/opt/ml/processing/`.

Also give the `run()` method a, where the `source` is the path the script writes output data to. For outputs, the `destination` defaults to an S3 bucket that the Amazon SageMaker Python SDK creates for you, following the format `s3://sagemaker--//output//`. You also give the `ProcessingOutput` value for `output_name`, to make it easier to retrieve these output artefacts after the job is run.

The arguments parameter in the `run()` method is command-line arguments in our `preprocess-scikit-text-to-bert-feature-store.py` script.

Note that we sharing the data using `ShardedByS3Key` to spread the transformations across all worker nodes in the cluster.

**Track the `Experiment`**

We will track every step of this experiment throughout the `prepare`, `train`, `optimize`, and `deploy`.

**Concepts**

**Experiment**: A collection of related Trials. Add Trials to an Experiment that you wish to compare together.

**Trial**: A description of a multi-step machine learning workflow. Each step in the workflow is described by a Trial Component. There is no relationship between Trial Components such as ordering.

**Trial Component**: A description of a single step in a machine learning workflow. For example data cleaning, feature extraction, model training, model evaluation, etc.

**Tracker**: A logger of information about a single TrialComponent.

![](https://raw.githubusercontent.com/smartworkz-kyriacos/data-science-on-aws/1bc7efe6931b75614b570f5f1c6f1c762abd8973/06_prepare/img/sagemaker-experiments.png =90%x)

**Create the `Experiment`**

In \[ \]:

    import time
    from smexperiments.experiment import Experiment
    
    timestamp = int(time.time())
    
    experiment = Experiment.create(
        experiment_name="Amazon-Customer-Reviews-BERT-Experiment-{}".format(timestamp),
        description="Amazon Customer Reviews BERT Experiment",
        sagemaker_boto_client=sm,
    )
    
    experiment_name = experiment.experiment_name
    print("Experiment name: {}".format(experiment_name))
    

**Create the `Trial`**

In \[ \]:

    import time
    from smexperiments.trial import Trial
    
    timestamp = int(time.time())
    
    trial = Trial.create(
        trial_name="trial-{}".format(timestamp), experiment_name=experiment_name, sagemaker_boto_client=sm
    )
    
    trial_name = trial.trial_name
    print("Trial name: {}".format(trial_name))
    

**Create the `Experiment Config`**

In \[ \]:

    experiment_config = {
        "ExperimentName": experiment_name,
        "TrialName": trial_name,
        "TrialComponentDisplayName": "prepare",
    }
    

In \[ \]:

    print(experiment_name)
    

In \[ \]:

    %store experiment_name
    

In \[ \]:

    print(trial_name)
    

In \[ \]:

    %store trial_name
    

**Create Feature Store and Feature Group**

In \[ \]:

    featurestore_runtime = boto3.Session().client(service_name="sagemaker-featurestore-runtime", region_name=region)
    

In \[ \]:

    timestamp = int(time.time())
    
    feature_store_offline_prefix = "reviews-feature-store-" + str(timestamp)
    
    print(feature_store_offline_prefix)
    

In \[ \]:

    feature_group_name = "reviews-feature-group-" + str(timestamp)
    
    print(feature_group_name)
    

In \[ \]:

    from sagemaker.feature_store.feature_definition import (
        FeatureDefinition,
        FeatureTypeEnum,
    )
    
    feature_definitions = [
        FeatureDefinition(feature_name="input_ids", feature_type=FeatureTypeEnum.STRING),
        FeatureDefinition(feature_name="input_mask", feature_type=FeatureTypeEnum.STRING),
        FeatureDefinition(feature_name="segment_ids", feature_type=FeatureTypeEnum.STRING),
        FeatureDefinition(feature_name="label_id", feature_type=FeatureTypeEnum.INTEGRAL),
        FeatureDefinition(feature_name="review_id", feature_type=FeatureTypeEnum.STRING),
        FeatureDefinition(feature_name="date", feature_type=FeatureTypeEnum.STRING),
        FeatureDefinition(feature_name="label", feature_type=FeatureTypeEnum.INTEGRAL),
        #    FeatureDefinition(feature_name='review_body', feature_type=FeatureTypeEnum.STRING)
    ]
    

In \[ \]:

    from sagemaker.feature_store.feature_group import FeatureGroup
    
    feature_group = FeatureGroup(name=feature_group_name, feature_definitions=feature_definitions, sagemaker_session=sess)
    
    print(feature_group)
    

**Set the Processing Job Hyper-Parameters**

In \[ \]:

    processing_instance_type = "ml.c5.2xlarge"
    processing_instance_count = 2
    train_split_percentage = 0.90
    validation_split_percentage = 0.05
    test_split_percentage = 0.05
    balance_dataset = True
    max_seq_length = 64
    

**Choosing a `max_seq_length` for BERT**

Since a smaller `max_seq_length` leads to faster training and lower resource utilization, we want to find the smallest review length that captures `80%` of our reviews.

Remember our distribution of review lengths from a previous section?

    mean         51.683405
    std         107.030844
    min           1.000000
    10%           2.000000
    20%           7.000000
    30%          19.000000
    40%          22.000000
    50%          26.000000
    60%          32.000000
    70%          43.000000
    80%          63.000000
    90%         110.000000
    100%       5347.000000
    max        5347.000000
    

![](https://raw.githubusercontent.com/smartworkz-kyriacos/data-science-on-aws/1bc7efe6931b75614b570f5f1c6f1c762abd8973/06_prepare/img/review_word_count_distribution.png)

Review length `63` represents the `80th` percentile for this dataset. However, it's best to stick with powers-of-2 when using BERT. So let's choose `64` as this is the smallest power-of-2 greater than `63`. Reviews with length > `64` will be truncated to `64`.

In \[ \]:

    from sagemaker.sklearn.processing import SKLearnProcessor
    
    processor = SKLearnProcessor(
        framework_version="0.23-1",
        role=role,
        instance_type=processing_instance_type,
        instance_count=processing_instance_count,
        env={"AWS_DEFAULT_REGION": region},
        max_runtime_in_seconds=7200,
    )
    

In \[ \]:

    from sagemaker.processing import ProcessingInput, ProcessingOutput
    
    processor.run(
        code="preprocess-scikit-text-to-bert-feature-store.py",
        inputs=[
            ProcessingInput(
                input_name="raw-input-data",
                source=raw_input_data_s3_uri,
                destination="/opt/ml/processing/input/data/",
                s3_data_distribution_type="ShardedByS3Key",
            )
        ],
        outputs=[
            ProcessingOutput(
                output_name="bert-train", s3_upload_mode="EndOfJob", source="/opt/ml/processing/output/bert/train"
            ),
            ProcessingOutput(
                output_name="bert-validation",
                s3_upload_mode="EndOfJob",
                source="/opt/ml/processing/output/bert/validation",
            ),
            ProcessingOutput(
                output_name="bert-test", s3_upload_mode="EndOfJob", source="/opt/ml/processing/output/bert/test"
            ),
        ],
        arguments=[
            "--train-split-percentage",
            str(train_split_percentage),
            "--validation-split-percentage",
            str(validation_split_percentage),
            "--test-split-percentage",
            str(test_split_percentage),
            "--max-seq-length",
            str(max_seq_length),
            "--balance-dataset",
            str(balance_dataset),
            "--feature-store-offline-prefix",
            str(feature_store_offline_prefix),
            "--feature-group-name",
            str(feature_group_name),
        ],
        experiment_config=experiment_config,
        logs=True,
        wait=False,
    )
    

In \[ \]:

    scikit_processing_job_name = processor.jobs[-1].describe()["ProcessingJobName"]
    print(scikit_processing_job_name)
    

In \[ \]:

    from IPython.core.display import display, HTML
    
    display(
        HTML(
            'Review {}#/processing-jobs/{}">Processing Job'.format(
                region, scikit_processing_job_name
            )
        )
    )
    

In \[ \]:

    from IPython.core.display import display, HTML
    
    display(
        HTML(
            'Review {}#logStream:group=/aws/sagemaker/ProcessingJobs;prefix={};streamFilter=typeLogStreamPrefix">CloudWatch Logs After About 5 Minutes'.format(
                region, scikit_processing_job_name
            )
        )
    )
    

In \[ \]:

    from IPython.core.display import display, HTML
    
    display(
        HTML(
            'Review {}/{}/?region={}&tab=overview">S3 Output Data After The Processing Job Has Completed'.format(
                bucket, scikit_processing_job_name, region
            )
        )
    )
    

**Monitor the Processing Job**

In \[ \]:

    running_processor = sagemaker.processing.ProcessingJob.from_processing_name(
        processing_job_name=scikit_processing_job_name, sagemaker_session=sess
    )
    
    processing_job_description = running_processor.describe()
    
    print(processing_job_description)
    

In \[ \]:

    running_processor.wait(logs=False)
    

_Please Wait Until the ^^ Processing Job ^^ Completes Above._

**Inspect the Processed Output Data**

Take a look at a few rows of the transformed dataset to make sure the processing was successful.

In \[ \]:

    processing_job_description = running_processor.describe()
    
    output_config = processing_job_description["ProcessingOutputConfig"]
    for output in output_config["Outputs"]:
        if output["OutputName"] == "bert-train":
            processed_train_data_s3_uri = output["S3Output"]["S3Uri"]
        if output["OutputName"] == "bert-validation":
            processed_validation_data_s3_uri = output["S3Output"]["S3Uri"]
        if output["OutputName"] == "bert-test":
            processed_test_data_s3_uri = output["S3Output"]["S3Uri"]
    
    print(processed_train_data_s3_uri)
    print(processed_validation_data_s3_uri)
    print(processed_test_data_s3_uri)
    

In \[ \]:

    !aws s3 ls $processed_train_data_s3_uri/
    

In \[ \]:

    !aws s3 ls $processed_validation_data_s3_uri/
    

In \[ \]:

    !aws s3 ls $processed_test_data_s3_uri/
    

**Pass Variables to the Next Notebook(s)**

In \[ \]:

    %store raw_input_data_s3_uri
    

In \[ \]:

    %store max_seq_length
    

In \[ \]:

    %store train_split_percentage
    

In \[ \]:

    %store validation_split_percentage
    

In \[ \]:

    %store test_split_percentage
    

In \[ \]:

    %store balance_dataset
    

In \[ \]:

    %store feature_store_offline_prefix
    

In \[ \]:

    %store feature_group_name
    

In \[ \]:

    %store processed_train_data_s3_uri
    

In \[ \]:

    %store processed_validation_data_s3_uri
    

In \[ \]:

    %store processed_test_data_s3_uri
    

In \[ \]:

    %store
    

**Query The Feature Store**

In \[ \]:

    feature_store_query = feature_group.athena_query()
    

In \[ \]:

    feature_store_table = feature_store_query.table_name
    

In \[ \]:

    query_string = """
    SELECT input_ids, input_mask, segment_ids, label_id, split_type  FROM "{}" WHERE split_type='train' LIMIT 5
    """.format(
        feature_store_table
    )
    
    print("Running " + query_string)
    

In \[ \]:

    feature_store_query.run(
        query_string=query_string,
        output_location="s3://" + bucket + "/" + feature_store_offline_prefix + "/query_results/",
    )
    
    feature_store_query.wait()
    

In \[ \]:

    feature_store_query.as_dataframe()
    

**Show the Experiment Tracking Lineage**

In \[ \]:

    from sagemaker.analytics import ExperimentAnalytics
    
    import pandas as pd
    
    pd.set_option("max_colwidth", 500)
    # pd.set_option("max_rows", 100)
    
    experiment_analytics = ExperimentAnalytics(
        sagemaker_session=sess, experiment_name=experiment_name, sort_by="CreationTime", sort_order="Descending"
    )
    
    experiment_analytics_df = experiment_analytics.dataframe()
    experiment_analytics_df
    

In \[ \]:

    trial_component_name = experiment_analytics_df.TrialComponentName[0]
    print(trial_component_name)
    

In \[ \]:

    trial_component_description = sm.describe_trial_component(TrialComponentName=trial_component_name)
    trial_component_description
    

**Show SageMaker ML Lineage Tracking**

Amazon SageMaker ML Lineage Tracking creates and stores information about the steps of a machine learning (ML) workflow from data preparation to model deployment.

Amazon SageMaker Lineage enables events that happen within SageMaker to be traced via a graph structure. The data simplifies generating reports, making comparisons, or discovering relationships between events. For example, easily trace both how a model was generated and where the model was deployed.

The lineage graph is created automatically by SageMaker and you can directly create or modify your graphs.

**Key Concepts**

* **Lineage Graph** - A connected graph tracing your machine learning workflow end to end.
* **Artefacts** - Represents a URI addressable object or data. Artefacts are typically inputs or outputs to Actions.
* **Actions** - Represents an action taken such as a computation, transformation, or job.
* **Contexts** - Provides a method to logically group other entities.
* **Associations** - A directed edge in the lineage graph that links two entities.
* **Lineage Traversal** - Starting from an arbitrary point trace the lineage graph to discover and analyze relationships between steps in your workflow.
* **Experiments** - Experiment entities (Experiments, Trials, and Trial Components) are also part of the lineage graph and can be associated with Artifacts, Actions, or Contexts.

**Show Lineage Artifacts For Our Processing Job**

In \[ \]:

    from sagemaker.lineage.visualizer import LineageTableVisualizer
    
    lineage_table_viz = LineageTableVisualizer(sess)
    lineage_table_viz_df = lineage_table_viz.show(processing_job_name=scikit_processing_job_name)
    lineage_table_viz_df
    

**Release Resources**

In \[ \]:

    %%html
    
    <p><b>Shutting down your kernel for this notebook to release resources.b>p>
    <button class="sm-command-button" data-commandlinker-command="kernelmenu:shutdown" style="display:none;">Shutdown Kernelbutton>
            
    <script>
    try {
        els = document.getElementsByClassName("sm-command-button");
        els[0].click();
    }
    catch(err) {
        // NoOp
    }    
    script>
    

In \[ \]:

    %%javascript
    
    try {
        Jupyter.notebook.save_checkpoint();
        Jupyter.notebook.session.delete();
    }
    catch(err) {
        // NoOp
    }
    

In \[ \]:

     