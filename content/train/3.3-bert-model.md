+++
chapter = false
title = "3.3 BERT DL Model"
weight = 3

+++
For our Amazon Customer Reviews Dataset, we can safely reuse the default BERT models because they share a similar vocabulary and language representation. There is no doubt that training BERT from scratch to learn the specific Amazon.com product catalogue would improve accuracy on some tasks, such as entity recognition. However, the default BERT models perform very well on our review text, so we will keep things simple and “fine-tune” a default BERT model to create a custom text classifier using our Amazon Customer Reviews Dataset.

Let’s reuse the language understanding and semantics learned by the pre-trained BERT model to learn a new, domain-specific NLP task using the Amazon Customer Reviews Dataset. This process, called “fine-tuning,” is shown in Figure 7-16.

![](/images/bert.png)

_Figure 7-16. We can fine-tune a pre-trained BERT model for a domain-specific task using a custom dataset._

The simplicity and bidirectional nature of the BERT self-attention mechanism allow us to fine-tune the base BERT models to a wide range of out-of-the-box, “downstream” NLP/NLU tasks, including text classification to analyze sentiment, entity recognition to detect a product name, and next sentence prediction to provide answers to natural language questions, as shown in Figure 7-17.

![](/images/bert-downstream.png)

_Figure 7-17. We can fine-tune the default BERT models to many “downstream” NLP and NLU tasks._

Since fine-tuning is a supervised training process (versus pre-training, which is unsupervised), masking and next-sentence prediction do not happen during fine-tuning

only during pre-training. As a result, fine-tuning is very fast and requires a relatively small number of samples, or reviews, in our case. This translates to lower processing power, lower cost, and faster training/tuning iterations.

Remember that we can use SageMaker JumpStart to try out these pre-trained models quickly and establish their usefulness as a solution for our machine-learning task. By quickly fine-tuning the pre-trained BERT model to our dataset, we can determine if BERT is a good fit or not.

Since we already generated the BERT embeddings from the raw review_body text in Chapter 6, we are ready to go! Let’s fine-tune BERT to create a custom text classifier that predicts star_rating from review_body using our dataset, as shown in Figure 7-18.

![](/images/bert-finetuning.png)

_Figure 7-18. We can fine-tune a BERT model to create a custom text classifier with our reviews dataset._

We can use this classifier to predict the sentiment of an incoming customer service email or Twitter comment, for example. So when a new email or comment enters the system, we first classify the email as negative (star_rating 1), neutral (star_rating 3), or positive (star_rating 5). This can help us determine the urgency of the response—or help us route the message to the right person, as shown in Figure 7-19.

![](/images/bert-classify.png)

_Figure 7-19. We can fine-tune BERT to classify review text into star_rating categories of 1 (worst) through 5 (best)._